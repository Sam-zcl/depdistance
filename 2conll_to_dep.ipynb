{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency distance calculation on a ConLL file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to calculate the dependency distance of a document. It assumes that the document has already been parsed into the ConLL format. To parse your documents into ConLL format, use [Spacy](https://spacy.io), [UDPipe](https://ufal.mff.cuni.cz/udpipe), Google's [Syntaxnet](https://github.com/tensorflow/models/tree/master/research/syntaxnet) (harder to set up, but better quality), or any other parser.\n",
    "\n",
    "The document in this example has two sentences. These have been parsed and tagged by UDPipe. Here's what the format looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "# newdoc id = doc1\n",
    "# newpar\n",
    "# sent_id = 1\n",
    "# text = I eat the pizza.\n",
    "1\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t2\tnsubj\t_\t_\n",
    "2\teat\teat\tVERB\tVBP\tMood=Ind|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
    "3\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t4\tdet\t_\t_\n",
    "4\tpizza\tpizza\tNOUN\tNN\tNumber=Sing\t2\tobj\t_\tSpaceAfter=No\n",
    "5\t.\t.\tPUNCT\t.\t_\t2\tpunct\t_\t_\n",
    "\n",
    "# sent_id = 2\n",
    "# text = The pizza, which I liked, was eaten by me.\n",
    "1\tThe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t2\tdet\t_\t_\n",
    "2\tpizza\tpizza\tNOUN\tNN\tNumber=Sing\t9\tnsubj:pass\t_\tSpaceAfter=No\n",
    "3\t,\t,\tPUNCT\t,\t_\t2\tpunct\t_\t_\n",
    "4\twhich\twhich\tPRON\tWDT\tPronType=Rel\t6\tobj\t_\t_\n",
    "5\tI\tI\tPRON\tPRP\tCase=Nom|Number=Sing|Person=1|PronType=Prs\t6\tnsubj\t_\t_\n",
    "6\tliked\tlike\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t2\tacl:relcl\t_\tSpaceAfter=No\n",
    "7\t,\t,\tPUNCT\t,\t_\t9\tpunct\t_\t_\n",
    "8\twas\tbe\tAUX\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t9\taux:pass\t_\t_\n",
    "9\teaten\teat\tVERB\tVBN\tTense=Past|VerbForm=Part|Voice=Pass\t0\troot\t_\t_\n",
    "10\tby\tby\tADP\tIN\t_\t11\tcase\t_\t_\n",
    "11\tme\tI\tPRON\tPRP\tCase=Acc|Number=Sing|Person=1|PronType=Prs\t9\tobl\t_\tSpaceAfter=No\n",
    "12\t.\t.\tPUNCT\t.\t_\t9\tpunct\t_\tSpacesAfter=\\n\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are separated by empty lines, and each line represents one word/token. Each lines contains 10 fields, which are tab-separated. The fields are further described in the ([documentation](http://universaldependencies.org/format.html)). Lines starting with `#` contain metadata for the following sentence.\n",
    "\n",
    "In a first step, we parse this document into a Pandas data frame. Because of the metadata, this is rather complex. A quick, but probably not very robust solution, is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_conll(conll):\n",
    "    lines = conll.split('\\n')\n",
    "    data = []  # hold the rows of the data frame\n",
    "    doc_ids = []  # holds document ids\n",
    "    sentence_ids = [1]  # holds sentence ids\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # the conll file might contain further annotations, \n",
    "        # these lines start with #\n",
    "        if line.startswith('# newdoc id ='):\n",
    "            doc_id = line.split('# newdoc id = ', 1)[1].strip()\n",
    "            doc_ids.append(doc_id)\n",
    "            sentence_ids = [1]\n",
    "        elif line=='# newdoc':\n",
    "            doc_ids.append(len(doc_ids)+1)\n",
    "            sentence_ids = [1]\n",
    "        elif line.startswith('# sent_id ='):\n",
    "            sent_id = line.split('# sent_id = ', 1)[1].strip()\n",
    "            # replace sentence id\n",
    "            sentence_ids[-1] = sent_id\n",
    "        elif line.startswith('#'):\n",
    "            continue # ignore other metadata\n",
    "        # the line is empty, start a new sentence\n",
    "        elif not line: \n",
    "            sentence_ids.append(len(sentence_ids)+1)\n",
    "        # the line has data, split by tab and add\n",
    "        else:\n",
    "            doc_id = doc_ids[-1] if doc_ids else None\n",
    "            data.append((doc_id, sentence_ids[-1], *line.split('\\t')))\n",
    "            \n",
    "    # turn into data frame\n",
    "    cols = ['docid', 'sentid', 'id', 'token', 'lemma', 'upos',\n",
    "            'xpos', 'feats', 'head', 'deprel', 'deps', 'misc']\n",
    "    df = pd.DataFrame(data, columns=cols)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "doc_df = parse_conll(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame `doc_df` now contains 19 rows (one for each token), and 12 columns. For dependency distance calculation, we only need a few columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>upos</th>\n",
       "      <th>head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>eat</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>pizza</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pizza</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>which</td>\n",
       "      <td>PRON</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>liked</td>\n",
       "      <td>VERB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>was</td>\n",
       "      <td>AUX</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>eaten</td>\n",
       "      <td>VERB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>me</td>\n",
       "      <td>PRON</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid sentid  id  token   upos head\n",
       "0   doc1      1   1      I   PRON    2\n",
       "1   doc1      1   2    eat   VERB    0\n",
       "2   doc1      1   3    the    DET    4\n",
       "3   doc1      1   4  pizza   NOUN    2\n",
       "4   doc1      1   5      .  PUNCT    2\n",
       "5   doc1      2   1    The    DET    2\n",
       "6   doc1      2   2  pizza   NOUN    9\n",
       "7   doc1      2   3      ,  PUNCT    2\n",
       "8   doc1      2   4  which   PRON    6\n",
       "9   doc1      2   5      I   PRON    6\n",
       "10  doc1      2   6  liked   VERB    2\n",
       "11  doc1      2   7      ,  PUNCT    9\n",
       "12  doc1      2   8    was    AUX    9\n",
       "13  doc1      2   9  eaten   VERB    0\n",
       "14  doc1      2  10     by    ADP   11\n",
       "15  doc1      2  11     me   PRON    9\n",
       "16  doc1      2  12      .  PUNCT    9"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df[['docid', 'sentid', 'id', 'token', 'upos', 'head']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `head` refers to the syntactic link between the token and its head. For instance, in the first sentence, \"now\" is linked to the token with id number `5`, which is the token \"post\". Dependency distance for each token is defined as the absolute distance between the token's id and the id of it's head. Each sentence contains exactly one \"root\", which in the first sentence is \"post\" (with a head of 0). Its dependency distance is defined as 0. The total mean dependency distance (MDD) for a sentence is defined as \n",
    "\n",
    "$$\n",
    "\\text{MDD}(s) = \\frac{1}{N_{s}-1}\\sum\\limits_{i=1}^n |\\text{DD}_{i}|,\n",
    "$$\n",
    "\n",
    "where $N_{s}$ refers the number of tokens in the sentence, and $DD_{i}$ refers to the dependency distance of the i-th token. To calculate MDD for the whole document,\n",
    "\n",
    "$$\n",
    "\\text{MDD}_{\\text{document}} = \\frac{1}{N-S}\\sum\\limits_{i=1}^n |\\text{DD}_{i}|,\n",
    "$$\n",
    "\n",
    "where $N$ refers to the the total number of tokens in the document, and $S$ refers to the total number of sentences. This weights all tokens in the document equally. (Note that this is different from weighting the MDD of the individual sentences).\n",
    "\n",
    "For punctuation, the dependency distance is not defined. This would suggest to remove all rows with punctuation, which is reasonable for the first sentence. However, in the second sentence, the removal of the comma (token 4), leads to a gap in the token id. The calculation of MDD has to take this gap into account and correct both the token id and the `head` column.\n",
    "\n",
    "Here's a way to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def calc_mdd(d, by_sentence=False):\n",
    "    # remove punctuation\n",
    "    d = d[d['upos'].str.lower() != 'punct'].copy()\n",
    "    # generate a new id\n",
    "    doc_sent_n = list(d.groupby(['docid', 'sentid'], sort=False).size())\n",
    "    d['new_id'] = list(chain.from_iterable([range(1, l+1) for l in doc_sent_n]))\n",
    "    # generate correspondence between old id and new id\n",
    "    # to correct the head column\n",
    "    ref = d[['docid', 'sentid', 'id', 'new_id']]\n",
    "    ref.columns = ['docid', 'sentid', 'head', 'new_head']\n",
    "    # merge the correspondence back to the data\n",
    "    d = pd.merge(d, ref, how='left', on=['docid', 'sentid', 'head'])\n",
    "    # calculate DD for each token\n",
    "    d['dd'] = (d['new_head'] - d['new_id']).abs()\n",
    "    if by_sentence==True:\n",
    "        agg = d.groupby(['docid', 'sentid']).agg(\n",
    "            {'dd': 'sum', 'token': 'count'}).reset_index()\n",
    "        agg['mdd'] = agg['dd'] / (agg['token'] - 1)\n",
    "        agg.columns = ['docid', 'sentid', 'sum_dd', 'n_tokens', 'mdd']\n",
    "    else:\n",
    "        agg = d.groupby(['docid']).agg(\n",
    "            {'dd': 'sum', 'token': 'count', 'sentid': 'nunique'}).\\\n",
    "            reset_index()\n",
    "        agg['mdd'] = agg['dd'] / (agg['token'] - agg['sentid'])\n",
    "        agg.columns = ['docid', 'sum_dd', 'n_tokens', 'n_sents', 'mdd']\n",
    "    return(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sum_dd</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_sents</th>\n",
       "      <th>mdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docid  sum_dd  n_tokens  n_sents       mdd\n",
       "0  doc1    20.0        13        2  1.818182"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mdd(doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>sum_dd</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>mdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docid sentid  sum_dd  n_tokens       mdd\n",
       "0  doc1      1     4.0         4  1.333333\n",
       "1  doc1      2    16.0         9  2.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mdd(doc_df, by_sentence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>sum_dd</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>mdd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docid sentid  sum_dd  n_tokens  mdd\n",
       "0  doc1      2    16.0         9  2.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that the results are the same if we take just one sentence\n",
    "calc_mdd(doc_df[doc_df.sentid==\"2\"], by_sentence=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
